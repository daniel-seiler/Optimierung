{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T23:14:04.516024Z",
     "start_time": "2025-01-10T23:14:04.513548Z"
    }
   },
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "import numpy as np\n",
    "\n",
    "x = Symbol('x')\n",
    "y = Symbol('y')\n",
    "f = 100*(y-x**2)**2+(1-x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c11e8192a3b06426",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T23:14:06.356130Z",
     "start_time": "2025-01-10T23:14:06.350280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1200 x^{2} - 400 y + 2 & - 400 x\\\\0 & 200\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[1200*x**2 - 400*y + 2, -400*x],\n",
       "[                    0,    200]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hessian_manual(f, varlist):\n",
    "    n = len(varlist)\n",
    "    hessian = zeros(n)\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            hessian[i, j] = f.diff(varlist[i]).diff(varlist[j])\n",
    "    return hessian\n",
    "\n",
    "hessian_manual(f, [x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c6f74d3f983b7c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T23:14:08.294520Z",
     "start_time": "2025-01-10T23:14:08.287026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.40451478920271566, 0.19989881420134903)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gradient_descent(f, start, learning_rate, iterations):\n",
    "    grad_x = diff(f, x)\n",
    "    grad_y = diff(f, y)\n",
    "    \n",
    "    grad_x_func = lambdify((x, y), grad_x)\n",
    "    grad_y_func = lambdify((x, y), grad_y)\n",
    "    \n",
    "    current_x, current_y = start\n",
    "    trajectory = [(current_x, current_y)]\n",
    "    for _ in range(iterations):\n",
    "        grad_x_val = grad_x_func(current_x, current_y)\n",
    "        grad_y_val = grad_y_func(current_x, current_y)\n",
    "        \n",
    "        current_x -= learning_rate * grad_x_val\n",
    "        current_y -= learning_rate * grad_y_val\n",
    "        \n",
    "        trajectory.append((current_x, current_y))\n",
    "\n",
    "    return current_x, current_y, trajectory\n",
    "\n",
    "min_x, min_y, trajectory = gradient_descent(f, (0.5, 0.5), 0.005, 100)\n",
    "min_x, min_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f5602f940566f8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T23:27:22.633744Z",
     "start_time": "2025-01-10T23:27:22.621562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.7335153249168256),\n",
       " np.float64(0.536226725563526),\n",
       " [(0.5, 0.5),\n",
       "  (np.float64(0.5098039215686274), np.float64(0.25)),\n",
       "  (np.float64(0.5143877627196569), np.float64(0.2599000384467512)),\n",
       "  (np.float64(0.5188934818669486), np.float64(0.26459477043573404)),\n",
       "  (np.float64(0.5232818860917139), np.float64(0.26925044552400534)),\n",
       "  (np.float64(0.5275595229114539), np.float64(0.27382393231170143)),\n",
       "  (np.float64(0.531732043281134), np.float64(0.2783190502145609)),\n",
       "  (np.float64(0.5358046620853659), np.float64(0.28273896585192976)),\n",
       "  (np.float64(0.5397822000329746), np.float64(0.2870866359124132)),\n",
       "  (np.float64(0.543669123255468), np.float64(0.2913648234724382)),\n",
       "  (np.float64(0.5474695779721184), np.float64(0.29557611558136926)),\n",
       "  (np.float64(0.5511874209680012), np.float64(0.2997229388049694)),\n",
       "  (np.float64(0.5548262464822347), np.float64(0.3038075730333566)),\n",
       "  (np.float64(0.55838941000619), np.float64(0.30783216378556544)),\n",
       "  (np.float64(0.561880049411657), np.float64(0.311798733207061)),\n",
       "  (np.float64(0.5653011037634554), np.float64(0.31570918992684616)),\n",
       "  (np.float64(0.5686553301169542), np.float64(0.319565337916181)),\n",
       "  (np.float64(0.5719453185561824), np.float64(0.3233688844704222)),\n",
       "  (np.float64(0.5751735056909342), np.float64(0.32712144741833293)),\n",
       "  (np.float64(0.5783421868001046), np.float64(0.3308245616487991)),\n",
       "  (np.float64(0.5814535267823226), np.float64(0.3344796850327271)),\n",
       "  (np.float64(0.5845095700529017), np.float64(0.3380882038076012)),\n",
       "  (np.float64(0.5875122495074728), np.float64(0.341651437483428)),\n",
       "  (np.float64(0.5904633946568318), np.float64(0.34517064332133107)),\n",
       "  (np.float64(0.5933647390240444), np.float64(0.3486470204296695)),\n",
       "  (np.float64(0.596217926883329), np.float64(0.3520817135170724)),\n",
       "  (np.float64(0.5990245194103516), np.float64(0.3554758163370546)),\n",
       "  (np.float64(0.6017860003050773), np.float64(0.35883037485480274)),\n",
       "  (np.float64(0.604503780940989), np.float64(0.3621463901631826)),\n",
       "  (np.float64(0.6071792050881537), np.float64(0.36542482117195124)),\n",
       "  (np.float64(0.6098135532521213), np.float64(0.3686665870914822)),\n",
       "  (np.float64(0.612408046665862), np.float64(0.37187256972997773)),\n",
       "  (np.float64(0.6149638509677912), np.float64(0.37504361562109667)),\n",
       "  (np.float64(0.6174820795952891), np.float64(0.37818053799713564)),\n",
       "  (np.float64(0.6199637969199443), np.float64(0.381284118621323)),\n",
       "  (np.float64(0.6224100211479482), np.float64(0.38435510949139395)),\n",
       "  (np.float64(0.6248217270066194), np.float64(0.38739423442538934)),\n",
       "  (np.float64(0.6271998482358611), np.float64(0.3904021905395344)),\n",
       "  (np.float64(0.6295452799014482), np.float64(0.39337964962708716)),\n",
       "  (np.float64(0.6318588805453458), np.float64(0.3963272594461926)),\n",
       "  (np.float64(0.6341414741867595), np.float64(0.3992456449240176)),\n",
       "  (np.float64(0.6363938521862839), np.float64(0.4021354092837565)),\n",
       "  (np.float64(0.6386167749843324), np.float64(0.40499713510049773)),\n",
       "  (np.float64(0.6408109737239718), np.float64(0.4078313852913895)),\n",
       "  (np.float64(0.6429771517673389), np.float64(0.41063870404506486)),\n",
       "  (np.float64(0.6451159861139788), np.float64(0.4134196176948396)),\n",
       "  (np.float64(0.6472281287286791), np.float64(0.41617463553981127)),\n",
       "  (np.float64(0.6493142077857036), np.float64(0.41890425061762765)),\n",
       "  (np.float64(0.6513748288357144), np.float64(0.42160894043237584)),\n",
       "  (np.float64(0.653410575901125), np.float64(0.42428916764075625)),\n",
       "  (np.float64(0.6554220125051308), np.float64(0.42694538069943977)),\n",
       "  (np.float64(0.6574096826392201), np.float64(0.42957801447627586)),\n",
       "  (np.float64(0.6593741116735617), np.float64(0.43218749082780006)),\n",
       "  (np.float64(0.6613158072143052), np.float64(0.4347742191452987)),\n",
       "  (np.float64(0.6632352599114937), np.float64(0.437338596871508)),\n",
       "  (np.float64(0.6651329442209966), np.float64(0.4398810099898666)),\n",
       "  (np.float64(0.6670093191235893), np.float64(0.44240183348809137)),\n",
       "  (np.float64(0.6688648288040678), np.float64(0.44490143179771413)),\n",
       "  (np.float64(0.6706999032930535), np.float64(0.447380159211095)),\n",
       "  (np.float64(0.6725149590739431), np.float64(0.44983836027731133)),\n",
       "  (np.float64(0.6743103996572694), np.float64(0.45227637017822736)),\n",
       "  (np.float64(0.6760866161245677), np.float64(0.4546945150859463)),\n",
       "  (np.float64(0.6778439876436865), np.float64(0.4570931125027686)),\n",
       "  (np.float64(0.6795828819573375), np.float64(0.4594724715846942)),\n",
       "  (np.float64(0.6813036558465504), np.float64(0.4618328934494405)),\n",
       "  (np.float64(0.6830066555705747), np.float64(0.4641746714698748)),\n",
       "  (np.float64(0.6846922172846645), np.float64(0.46649809155370175)),\n",
       "  (np.float64(0.6863606674370756), np.float64(0.4688034324101902)),\n",
       "  (np.float64(0.6880123231465178), np.float64(0.4710909658046678)),\n",
       "  (np.float64(0.689647492561212), np.float64(0.47336095680146845)),\n",
       "  (np.float64(0.6912664752006283), np.float64(0.47561366399596705)),\n",
       "  (np.float64(0.6928695622809055), np.float64(0.4778493397363009)),\n",
       "  (np.float64(0.6944570370248864), np.float64(0.4800682303353335)),\n",
       "  (np.float64(0.6960291749576409), np.float64(0.48227057627338443)),\n",
       "  (np.float64(0.69758624418829), np.float64(0.48445661239221427)),\n",
       "  (np.float64(0.6991285056788934), np.float64(0.4866265680807245)),\n",
       "  (np.float64(0.7006562135011121), np.float64(0.4887806674528024)),\n",
       "  (np.float64(0.7021696150813121), np.float64(0.4909191295177159)),\n",
       "  (np.float64(0.7036689514347346), np.float64(0.493042168343438)),\n",
       "  (np.float64(0.7051544573893157), np.float64(0.495149993213259)),\n",
       "  (np.float64(0.706626361799706), np.float64(0.49724280877602023)),\n",
       "  (np.float64(0.7080848877520044), np.float64(0.4993208151902889)),\n",
       "  (np.float64(0.7095302527596892), np.float64(0.5013842082627686)),\n",
       "  (np.float64(0.7109626689511996), np.float64(0.5034331795812284)),\n",
       "  (np.float64(0.7123823432495967), np.float64(0.5054679166422131)),\n",
       "  (np.float64(0.7137894775447027), np.float64(0.5074886029737862)),\n",
       "  (np.float64(0.7151842688580982), np.float64(0.5094954182535396)),\n",
       "  (np.float64(0.7165669095013322), np.float64(0.5114885384220924)),\n",
       "  (np.float64(0.7179375872276795), np.float64(0.5134681357922903)),\n",
       "  (np.float64(0.7192964853777625), np.float64(0.5154343791543019)),\n",
       "  (np.float64(0.720643783019334), np.float64(0.5173874338768016)),\n",
       "  (np.float64(0.7219796550815023), np.float64(0.5193274620044169)),\n",
       "  (np.float64(0.7233042724836647), np.float64(0.521254622351605)),\n",
       "  (np.float64(0.7246178022593981), np.float64(0.5231690705931233)),\n",
       "  (np.float64(0.7259204076755452), np.float64(0.5250709593512402)),\n",
       "  (np.float64(0.7272122483467193), np.float64(0.5269604382798297)),\n",
       "  (np.float64(0.728493480345438), np.float64(0.5288376541454906)),\n",
       "  (np.float64(0.7297642563080898), np.float64(0.5307027509058091)),\n",
       "  (np.float64(0.7310247255369177), np.float64(0.5325558697848994)),\n",
       "  (np.float64(0.7322750340982042), np.float64(0.5343971493463258)),\n",
       "  (np.float64(0.7335153249168256), np.float64(0.536226725563526))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def newton(f, start, learning_rate, iterations):\n",
    "    gradient = Matrix([diff(f, val) for val in [x, y]])\n",
    "    hessian = hessian_manual(f, [x, y])\n",
    "\n",
    "    grad_func = lambdify([x, y], gradient, \"numpy\")\n",
    "    hessian_func = lambdify([x, y], hessian, \"numpy\")\n",
    "\n",
    "    current_x, current_y = start\n",
    "    trajectory = [(current_x, current_y)]\n",
    "\n",
    "    for i in range(iterations):\n",
    "        grad_val = np.array(grad_func(current_x, current_y), dtype=float).flatten()\n",
    "        hessian_val = np.array(hessian_func(current_x, current_y), dtype=float)\n",
    "\n",
    "        try:\n",
    "            hessian_inv = np.linalg.inv(hessian_val)\n",
    "            step = hessian_inv @ grad_val\n",
    "        except np.linalg.LinAlgError:\n",
    "            print(f\"Abbruch bei Iteration {i}: Hesse-Matrix ist nicht invertierbar.\")\n",
    "            break\n",
    "\n",
    "        current_x -= learning_rate * step[0]\n",
    "        current_y -= learning_rate * step[1]\n",
    "\n",
    "        trajectory.append((current_x, current_y))\n",
    "\n",
    "    return current_x, current_y, trajectory\n",
    "\n",
    "min_x, min_y, trajectory = newton(f, (0.5, 0.5), 1, 100)\n",
    "min_x, min_y, trajectory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
